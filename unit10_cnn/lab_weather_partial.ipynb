{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6a540bfa",
      "metadata": {
        "id": "6a540bfa"
      },
      "source": [
        "# Lab: Fine-tuning an Image Model for Weather Classification\n",
        "\n",
        "As discussed in class, training large computer vision models from scratch takes enormous amounts of data and computational training.  If you don't have days to wait, it is best to **fine tune** a pre-existing well-trained model.  In this lab, we will demonstrate how to fine tune a model for weather classification.  \n",
        "\n",
        "In going through this lab, you will learn to:\n",
        "\n",
        "* Download a dataset form **Kagglehub**\n",
        "* Use operating system python calls to explore files and perform tasks such as splitting the data into training and test\n",
        "* Download a **base model**.  In this lab, we use the simple MobileNetV2 since it is computationally easy\n",
        "* **Fine tune** the model with a simple **classifier head**\n",
        "* Add progress bars in trianing and evalating while training is occuring\n",
        "\n",
        "\n",
        "## Using Google Colab's Free Tier GPU\n",
        "The lab is greatly assisted with a GPU.  While most laptops have GPUs, they are generally not useful for ML.  So, assuming you do not have access to a specific machine designed for ML, I suggest you use Google colab.  You can follow the instructions on this [Stanford blog](https://rcpedia.stanford.edu/blog/2024/03/28/train-machine-learning-models-on-colab-gpu/#:~:text=in%20your%20Drive.-,Switch%20to%20Using%20a%20GPU,Click%20Save%20.) to select a GPU.  \n",
        "\n",
        "The free tier of Google Colab comes with a T4 Telsa GPU which is sufficient for this lab.  For more money, you can select the A100 GPU which a bit faster.  But, for this relatively small model, there is not much gain going to the A100 GPU (I found it only goes about 50% faster).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c7af9aa",
      "metadata": {
        "id": "6c7af9aa"
      },
      "source": [
        "\n",
        "\n",
        "## Loading the dataset from Kaggle\n",
        "\n",
        "We will use a [Kaggle dataset](https://www.kaggle.com/datasets/jehanbhathena/weather-dataset) with images of scenes in different weather conditions like frost, rain, ...  \n",
        "First, we download the data set with the following command.  The total dataset is almost 1 GB large, so the downloading could take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8af33b6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8af33b6f",
        "outputId": "ccfa6ae3-d0cd-4478-a4fd-84dca9479fc7"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jehanbhathena/weather-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cbc61de",
      "metadata": {
        "id": "3cbc61de"
      },
      "source": [
        "After the download, there will be one sub-folder for each category.  The directory structure will look like:\n",
        "\n",
        "~~~\n",
        "dataset_path/\n",
        "â”œâ”€â”€ dew/\n",
        "â”‚   â”œâ”€â”€ image1.jpg\n",
        "â”‚   â”œâ”€â”€ image2.jpg\n",
        "â”‚   â””â”€â”€ ...\n",
        "â”œâ”€â”€ fogsmog/\n",
        "â”‚   â”œâ”€â”€ image1.jpg\n",
        "â”‚   â”œâ”€â”€ image2.jpg\n",
        "â”‚   â””â”€â”€ ...\n",
        "â”œâ”€â”€ frost/\n",
        "â”‚   â”œâ”€â”€ image1.jpg\n",
        "â”‚   â”œâ”€â”€ image2.jpg\n",
        "â”‚   â””â”€â”€ ...\n",
        "â”œâ”€â”€ glaze/\n",
        "â”‚   â”œâ”€â”€ image1.jpg\n",
        "â”‚   â”œâ”€â”€ image2.jpg\n",
        "â”‚   â””â”€â”€ ...\n",
        "~~~\n",
        "\n",
        "\n",
        " Print the names of the sub-folders and the number of files in each sub-folder.  Also, create a list `categories` with  Some useful commands are:\n",
        "* `os.listdir` which lists all the directories\n",
        "* `os.path.join(dataset_path, d)`:  creates the path for the subfolder `d` in `dataset_path`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3dabd7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3dabd7b",
        "outputId": "2150fe71-a660-4a26-8faf-853f260d2fd6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "dataset_path = os.path.join(path, \"dataset\")\n",
        "\n",
        "\n",
        "# TODO:  Populate the lists below with category names and their corresponding file counts\n",
        "#   categories = ...\n",
        "#   file_counts = ...\n",
        "\n",
        "\n",
        "# TODO: Create a DataFrame from the lists and print it\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b378f8fc",
      "metadata": {
        "id": "b378f8fc"
      },
      "source": [
        "Next, randomly select an image from each category and print it.\n",
        "\n",
        "* Use the `fig,axs = plt.subplot(...)` to create an array to plot the images.  \n",
        "* Loop over the categories\n",
        "* In each category directory, randomly select an image file\n",
        "* Use the `img = Image.open(img_path)` to load the image.\n",
        "* Use `ax[i].imshow(img)` to display the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac76b2e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ac76b2e8",
        "outputId": "76cdd280-b6da-4323-80b9-90ae82badce2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "nclass = len(categories)\n",
        "nrow = 2\n",
        "ncol = (nclass + 1) // nrow\n",
        "\n",
        "# Create the subplot grid with nrow and ncol rows and columns\n",
        "#   fig, axs = plt.subplots(...)\n",
        "fig, axs = plt.subplots(nrow, ncol, figsize=(15, 5))\n",
        "\n",
        "# TODO:  Randomly select an image from each category and display it\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa73d861",
      "metadata": {
        "id": "aa73d861"
      },
      "source": [
        "## Creating a Training and Test Datasets\n",
        "This particular dataset has a single set of images.  Write code that will create two directories `train` and `test`, each with a sub-folder structure  with one set of images per class.  You should randomly place a fraction `split_ratio` of the images in the `train` folder, and the remaining in the `test` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3fd2f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d3fd2f0",
        "outputId": "6693fce5-fd05-4aea-ad08-43b1c6700fc1"
      },
      "outputs": [],
      "source": [
        "# Set the training and test directory paths\n",
        "train_dir = os.path.normpath(os.path.join(path, '..',\"train\"))\n",
        "test_dir = os.path.normpath(os.path.join(path, '..',\"test\"))\n",
        "\n",
        "# TODO:  Loop over each category and split the images into training and test sets\n",
        "# in each category according to the split_ratio\n",
        "\n",
        "\n",
        "# TODO:  Count the number of images in each category for training and test sets\n",
        "# and display the counts in a DataFrame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0ada97",
      "metadata": {
        "id": "fb0ada97"
      },
      "source": [
        "## Downloading the base model\n",
        "\n",
        "Pytorch ha a number of excellent pre-trained models that we can use for fine tuning.    For this lab, to make the training easy, we will use a lightweight model called **MobileNetV2**.  MobileNetV2 is a CNN developed by Google that targeting mobile devices that are computationally limited. It uses an architecture with inverted residual blocks and linear bottlenecks to improve performance while keeping computational costs low. A nice summary of the model can be found in this [Medium post](https://medium.com/codex/a-summary-of-the-mobilenetv2-inverted-residuals-and-linear-bottlenecks-paper-e19b187cb78a).  We can download the model as follows.\n",
        "\n",
        "First we download the key packages and set a `transform` needed for the MobileNetV2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da10bd3",
      "metadata": {
        "id": "7da10bd3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66aefb06",
      "metadata": {
        "id": "66aefb06"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22217382",
      "metadata": {},
      "source": [
        "Next, we create `DataLoader` classes to load the models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d8b9ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5d8b9ec",
        "outputId": "ea5f5c7c-4e81-4916-ceb8-71e23114a92c"
      },
      "outputs": [],
      "source": [
        "# TODO:  Create the training and test datasets.  Use the `datasets.ImageFolder` class\n",
        "# with the appropriate directory and transform.\n",
        "#    train_dataset = ...\n",
        "#    test_dataset = ...\n",
        "\n",
        "\n",
        "# TODO:  Create the training and test dataloaders.  Use a batch size of 16.\n",
        "#    train_loader = ...\n",
        "#    test_loader = ...\n",
        "\n",
        "\n",
        "# TODO:  Print the number of classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0Oi0Pcpcpvmt",
      "metadata": {
        "id": "0Oi0Pcpcpvmt"
      },
      "source": [
        "Now we download the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20b895d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20b895d0",
        "outputId": "948a0591-04d5-4b4d-ff46-6ddef2cda3fa"
      },
      "outputs": [],
      "source": [
        "model = models.mobilenet_v2(pretrained=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i4DUMAYzqpHU",
      "metadata": {
        "id": "i4DUMAYzqpHU"
      },
      "source": [
        "The MobileNetV2 model has two main components:\n",
        "- `model.features`\n",
        "This is the **base model**, also known as the **backbone**. It contains the convolutional layers that extract features from the input image.\n",
        "ðŸ‘‰ In transfer learning, we typically freeze this part to retain the pretrained feature extractor.\n",
        "- `model.classifier`\n",
        "This is the **classifier head**. It takes the output from `model.features` and maps it to the final class predictions.\n",
        "ðŸ‘‰ We **replace and train** this part to adapt the model to our specific task (e.g., weather classification)\n",
        "\n",
        "\n",
        "First, we can see all the layers with the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uNYS3iiQpcDw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNYS3iiQpcDw",
        "outputId": "ca020bd3-b915-4682-99a4-4dc2cf54e9c3"
      },
      "outputs": [],
      "source": [
        "model.features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Fw7bGZyJsbg3",
      "metadata": {
        "id": "Fw7bGZyJsbg3"
      },
      "source": [
        "To get some insight into the model:\n",
        "\n",
        "* Loop over the layers in the model with `name, layer in model.features.named_children`\n",
        "* For each layer, get the layer type with `layer_type = layer.__class__.__name__`\n",
        "* Get the total number of parameters in the layers\n",
        "    * You can loop over the parameters with `for p in layers.parameters`\n",
        "    * Then count the number of paramters with `p.numel()`\n",
        "* Print a `pandas.DataFrame` with the layer `name`, `layer_type`, and number of elements.\n",
        "* Also, print the total number of paramters.\n",
        "\n",
        "You should see that the model has about 2.2M parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ykm2Cqsaf-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5ykm2Cqsaf-",
        "outputId": "63c3f875-f47f-46d4-f3ab-ec33ad191a82"
      },
      "outputs": [],
      "source": [
        "# TODO:  Get the layer names, types, and number of parameters in each layer of\n",
        "# model.features\n",
        "#    layer_data = []\n",
        "#    for name, layer in model.features.named_children():\n",
        "#       layer_datai = {'name': ..., 'layer_type': ..., 'num_param': ...}\n",
        "#       layer_data.append(layer_datai)\n",
        "\n",
        "\n",
        "# TODO:  Create a pandas DataFrame and print the layer data\n",
        "\n",
        "\n",
        "# TODO:  Print the total number of parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tC9TbqhN3WB5",
      "metadata": {
        "id": "tC9TbqhN3WB5"
      },
      "source": [
        "We will next the number of features from the final layer of the features model.  This value will be the number of inputs to the classifier head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gKgbRYHy3I7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKgbRYHy3I7c",
        "outputId": "26d487c2-5efc-4f59-9d0b-6bd204518b48"
      },
      "outputs": [],
      "source": [
        "# TODO:  Get the number of outputs of the final layer of model.features\n",
        "#    num_features = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I8Nlwu9Uw8-B",
      "metadata": {
        "id": "I8Nlwu9Uw8-B"
      },
      "source": [
        "Now, let's look at the classifier.  This is a simple model with two layers:\n",
        "* A dropout layer\n",
        "* A fully connected layer with 1000 output features for a 1000-way softmax (recall the original ImageNet has 1000 classes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "961utxJQtSsw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "961utxJQtSsw",
        "outputId": "21f66d73-8c4d-4c6e-a8db-68e08addbc83"
      },
      "outputs": [],
      "source": [
        "model.classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w9NTaaiExSmO",
      "metadata": {
        "id": "w9NTaaiExSmO"
      },
      "source": [
        "For fine-tuning, we will replace the classifer head with a small MLP:\n",
        "*  A `nn.Dropout` layer with 0.2 dropout\n",
        "*  A `nn.Linear` layer taking the `num_features` input to the `num_hidden` output\n",
        "* A ReLU activation\n",
        "* A final linear layer with the one output for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4YvN5n83pTcp",
      "metadata": {
        "id": "4YvN5n83pTcp"
      },
      "outputs": [],
      "source": [
        "num_hidden = 100\n",
        "\n",
        "# TODO:  Replace the classifier head\n",
        "#  model.classifier = nn.Sequential(...)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vLS2XdZTxjWu",
      "metadata": {
        "id": "vLS2XdZTxjWu"
      },
      "source": [
        "Next, we **freeze** the parameters in all the `model.features` layers, so we only retrain the final layer.  This will make the training much faster.  You can loop over `model.features.parameters()` and set `param.requires_grad = False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lvbP0blbpaco",
      "metadata": {
        "id": "lvbP0blbpaco"
      },
      "outputs": [],
      "source": [
        "# TODO:  Freeze all the parameters in model.features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8pvNO2UDyflz",
      "metadata": {
        "id": "8pvNO2UDyflz"
      },
      "source": [
        "To confirm we set everything correctly, loop over `model.parameters()` and find the total number of parameters that are trainable and total number that are fixed.  You should get that only about 129,000 are trainable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49-wB1jIycxd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49-wB1jIycxd",
        "outputId": "38bc4759-119e-423b-f261-aa5029ef4c4e"
      },
      "outputs": [],
      "source": [
        "# TODO:  Print the total number of trainable and fixed parameters\n",
        "#   trainable = ...\n",
        "#   fixed = ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NFfnrEpSyKiu",
      "metadata": {
        "id": "NFfnrEpSyKiu"
      },
      "source": [
        "## Loading the model to a GPU\n",
        "For training image models, it greatly helps to use a GPU.  \n",
        "* Use the `torch.cuda.is_available()` to see if a GPU is available.  \n",
        "* If so, print the number of GPUs with `torch.cuda.device_count()`\n",
        "* Also, print the GPU name with `torch.cudu.get_device_name` and `torch.cuda.get_current_device()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rF9pz6l2x7Yy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF9pz6l2x7Yy",
        "outputId": "fc256118-023b-45bb-a5cf-19646f247d16"
      },
      "outputs": [],
      "source": [
        "# TODO:  See if there is a GPU and what type of GPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_eVT9R5u0Kip",
      "metadata": {
        "id": "_eVT9R5u0Kip"
      },
      "source": [
        "Finally, we move the model to the GPU with the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642913d0",
      "metadata": {
        "id": "642913d0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8XOW24eR0emX",
      "metadata": {
        "id": "8XOW24eR0emX"
      },
      "source": [
        "## Training the model\n",
        "We are now ready to train our model.  First we select the loss function criterion and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l6rbT6yo0iv_",
      "metadata": {
        "id": "l6rbT6yo0iv_"
      },
      "outputs": [],
      "source": [
        "# TODO:  Set loss function and optimizer\n",
        "#   criterion = ...  (use cross entropy loss)\n",
        "#   optimizer = ...  (use Adam with a lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0U-F58MP7jSo",
      "metadata": {
        "id": "0U-F58MP7jSo"
      },
      "source": [
        "You can now train the model by completing the following code.  With a T4 GPU, each epoch should complete in a few minutes.  You should be able to get about 85% accuracy.  You can higher accuracy with a larger model, larger classifier head, and more time.  But, I want you to just understand the basic ideas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e7a5cff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e7a5cff",
        "outputId": "20e05184-0968-49bd-8480-86f69b9b6d5b"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "nepochs = 5\n",
        "for epoch in range(nepochs):  # Adjust epochs as needed\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=True)\n",
        "    for images, labels in loop:\n",
        "\n",
        "        # TODO:  Move the images to the GPU\n",
        "        #   images = images.to(...)\n",
        "        #   labels = labels.to(...)\n",
        "        \n",
        "\n",
        "        # TODO:  Perform the back-prop on the data\n",
        "        #    optimizer.zero_grad()\n",
        "        #    outputs = ...\n",
        "        #    loss = ...\n",
        "        #    ...\n",
        "        \n",
        "\n",
        "        # Update the running loss and progress bar\n",
        "        running_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss:.4f}\")\n",
        "\n",
        "    # Evaluation after each epoch\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      loop = tqdm(test_loader, desc=\"Evaluating\", leave=True)\n",
        "\n",
        "      for images, labels in loop:\n",
        "\n",
        "          # TODO:  Move the images and labels to the GPU\n",
        "          #   images = images.to(...)\n",
        "          #   labels = labels.to(...)\n",
        "          \n",
        "\n",
        "          # TODO:  Update the total number of correct and total number of images\n",
        "          #    correct += ...\n",
        "          #    total += ...\n",
        "          \n",
        "\n",
        "          # Update postfix with current accuracy\n",
        "          accuracy = 100 * correct / total\n",
        "          loop.set_postfix({'Accuracy': f'{accuracy:.2f}%'})\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}, Test Accuracy: {accuracy:.2f}%\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0abca79",
      "metadata": {
        "id": "b0abca79"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), \"mobilenetv2_weights.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v7DCf5-G8BfW",
      "metadata": {
        "id": "v7DCf5-G8BfW"
      },
      "source": [
        "## Evaluating the model\n",
        "\n",
        "Let's conclude by evaluating the model.  First we reset the model architecture and then load the parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sBcZPNfn7Tg4",
      "metadata": {
        "id": "sBcZPNfn7Tg4"
      },
      "outputs": [],
      "source": [
        "# Set parameters\n",
        "num_hidden = 100\n",
        "\n",
        "# Load base model\n",
        "model = models.mobilenet_v2()\n",
        "\n",
        "# TODO:  Rebuild the classifier head\n",
        "#  model.classifier = nn.Sequential(...)\n",
        "\n",
        "\n",
        "# Load weights\n",
        "model.load_state_dict(torch.load(\"mobilenetv2_weights.pth\"))\n",
        "model.to(device)\n",
        "model.eval();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mT-o61Sv9i4X",
      "metadata": {
        "id": "mT-o61Sv9i4X"
      },
      "source": [
        "Now run the model and create a confusion matrix.\n",
        "* Evaluate the model on the `test_loader` dataset\n",
        "* Add a `tqdm` loop to display the progress as it evaluates the data\n",
        "* Create a confusion matrix and display the confusion matrix with `ConfusionMatrixDisplay` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KzN53CJS9iU3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "KzN53CJS9iU3",
        "outputId": "a6b49980-93aa-4421-a2b4-80ca0c0e7b44"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "# TODO:  Evaluate the model on the test_loader dataset.\n",
        "#\n",
        "#  with torch.no_grad():\n",
        "#      for images, labels in test_loader:\n",
        "#        ...\n",
        "#\n",
        "#  cm  = confusion_matrix(...)\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cyKPre3PBBis",
      "metadata": {
        "id": "cyKPre3PBBis"
      },
      "source": [
        "Finally, print the top `k=10` confusion matrix pairs with the highest percent errors.  Your final list should be something like:\n",
        "~~~\n",
        "Top 10 pairs with the highest error:\n",
        "      snow ->      glaze:  error=0.08750\n",
        "     frost ->       snow:  error=0.07586\n",
        "     glaze ->       hail:  error=0.07563\n",
        "      rain ->  lightning:  error=0.07512\n",
        "      hail ->      glaze:  error=0.06250\n",
        "     glaze ->       snow:  error=0.05517\n",
        "     frost ->  sandstorm:  error=0.05303\n",
        "      snow ->      frost:  error=0.05128\n",
        " sandstorm ->      frost:  error=0.04487\n",
        "      hail ->       snow:  error=0.04138\n",
        "~~~\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E2DyasGz8Ic1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2DyasGz8Ic1",
        "outputId": "e65dbad3-b2fd-4c2c-fb12-06cfaf279025"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# Print the name of the category pair with the highest error.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8UxfJpeJ-3VS",
      "metadata": {
        "id": "8UxfJpeJ-3VS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1BZF4NX__5j6",
      "metadata": {
        "id": "1BZF4NX__5j6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
